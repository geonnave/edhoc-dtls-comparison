{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3e1bfe1d-2cc4-45ec-9cd3-6b25f0d1fdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics, rich\n",
    "from dataclasses import dataclass, field\n",
    "from IPython.display import display, display_markdown, Markdown\n",
    "from datetime import datetime\n",
    "\n",
    "def print_markdown(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e1fb8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class HandshakeSizes:\n",
    "    edhoc_csv_file: str\n",
    "    dtls_csv_file: str\n",
    "    dtls_cert_csv_file: str\n",
    "    edhoc_df: pd.DataFrame = None\n",
    "    dtls_df: pd.DataFrame = None\n",
    "    dtls_cert_df: pd.DataFrame = None\n",
    "\n",
    "    def enforce_int(df):\n",
    "        columns_to_convert = [col for col in df.columns if col not in ['_direction', '_data_no_radio']] # fixing this..\n",
    "        df[columns_to_convert] = df[columns_to_convert].astype(int)\n",
    "        return df\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.edhoc_df = pd.read_csv(self.edhoc_csv_file)\n",
    "        self.dtls_df = pd.read_csv(self.dtls_csv_file)\n",
    "        self.dtls_cert_df = pd.read_csv(self.dtls_cert_csv_file)\n",
    "\n",
    "        # annotate steps and calculate total\n",
    "        self.edhoc_df.insert(0, 'step', ['Message 1', 'Message 2', 'Message 3', 'Final Ack'])\n",
    "        self.edhoc_df.set_index('step', inplace=True)\n",
    "        self.edhoc_df.loc['_total'] = self.edhoc_df.drop('_direction', axis=1).sum(numeric_only=True)\n",
    "        self.edhoc_df = HandshakeSizes.enforce_int(self.edhoc_df)\n",
    "\n",
    "        dtls_steps = ['Client Hello', 'Server Hello', 'Client Hello (cookie)', 'Server Hello', 'Encrypted Extensions', 'Certificate', 'Certificate Verify', 'Server Finished', 'Client Finished', 'Ack']\n",
    "        self.dtls_df.insert(0, 'step', dtls_steps)\n",
    "        self.dtls_df.set_index('step', inplace=True)\n",
    "        self.dtls_df.loc['_total'] = self.dtls_df.drop('_direction', axis=1).sum(numeric_only=True)\n",
    "        self.dtls_df = HandshakeSizes.enforce_int(self.dtls_df)\n",
    "\n",
    "        dtls_cert_steps = ['Client Hello', 'Server Hello', 'Client Hello (cookie)', 'Server Hello', 'Encrypted Extensions', 'Certificate', 'Certificate Verify', '', '', 'Server Finished', 'Client Finished', 'Ack']\n",
    "        self.dtls_cert_df.insert(0, 'step', dtls_cert_steps)\n",
    "        self.dtls_cert_df.set_index('step', inplace=True)\n",
    "        self.dtls_cert_df.loc['_total'] = self.dtls_cert_df.drop('_direction', axis=1).sum(numeric_only=True)\n",
    "        self.dtls_cert_df = HandshakeSizes.enforce_int(self.dtls_cert_df)\n",
    "\n",
    "    def plot(self):\n",
    "        columns_to_drop = ['_sum', '_fragments', '_direction', '_data_no_radio', '_data_no_radio_len']\n",
    "        total_row_edhoc = self.edhoc_df.loc['_total'].drop(columns_to_drop)\n",
    "        total_row_dtls = self.dtls_df.loc['_total'].drop(['_sum', '_fragments', '_direction'])\n",
    "        total_row_dtls_cert = self.dtls_cert_df.loc['_total'].drop(['_sum', '_fragments', '_direction'])\n",
    "\n",
    "        color_dict = {\n",
    "            'IEEE 802.15.4': 'tab:blue',\n",
    "            '6LoWPAN': 'firebrick',\n",
    "            'CoAP': 'tab:green', \n",
    "            'Content': 'tab:orange'\n",
    "        }\n",
    "\n",
    "        # Columns to plot\n",
    "        columns_df1 = total_row_edhoc.index\n",
    "        columns_df2 = total_row_dtls.index\n",
    "        columns_df3 = total_row_dtls_cert.index\n",
    "\n",
    "        # Create a list of values for each DataFrame\n",
    "        values_df1 = total_row_edhoc.values\n",
    "        values_df2 = total_row_dtls.values\n",
    "        values_df3 = total_row_dtls_cert.values\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        bottom_value = 0\n",
    "        for i, col_name in enumerate(columns_df1):\n",
    "            ax.bar('EDHOC', values_df1[i], bottom=bottom_value, label=col_name, color=color_dict[col_name])\n",
    "            bottom_value += values_df1[i]\n",
    "\n",
    "        bottom_value = 0\n",
    "        for i, col_name in enumerate(columns_df2):\n",
    "            ax.bar('DTLS RPK', values_df2[i], bottom=bottom_value, label=col_name, color=color_dict[col_name])\n",
    "            bottom_value += values_df2[i]\n",
    "\n",
    "        bottom_value = 0\n",
    "        for i, col_name in enumerate(columns_df3):\n",
    "            ax.bar('DTLS Cert', values_df3[i], bottom=bottom_value, label=col_name, color=color_dict[col_name])\n",
    "            bottom_value += values_df3[i]\n",
    "\n",
    "        # Only display one legend entry per unique label\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        unique_labels = list(dict.fromkeys(labels).keys())\n",
    "        unique_handles = [handles[labels.index(lb)] for lb in unique_labels]\n",
    "\n",
    "        ax.set_ylabel('Total (bytes))')\n",
    "        ax.set_title('Accumulated bytes over the air for EDHOC and DTLS 1.3')\n",
    "        ax.legend(unique_handles, unique_labels)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def results(self, plot=True):\n",
    "        print_markdown(\"# Bytes over the air: \")\n",
    "        display(self.edhoc_df.style.set_caption(\"EDHOC:\"))\n",
    "        display(self.dtls_df.style.set_caption(\"DTLS RPK:\"))\n",
    "        display(self.dtls_cert_df.style.set_caption(\"DTLS Cert:\"))\n",
    "        if plot:\n",
    "            self.plot()\n",
    "\n",
    "# hs_sizes = HandshakeSizes(\"./results/edhoc_pcap.csv\", \"./results/dtls_rpk_pcap.csv\", \"./results/dtls_cert_pcap.csv\")\n",
    "# hs_sizes.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ba5080e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Handshake:\n",
    "    _df: pd.DataFrame\n",
    "    start: float\n",
    "    end: float\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df.iloc[self.start:self.end]\n",
    "\n",
    "    def with_offset(self, offset):\n",
    "        return Handshake(self._df, self.start-offset, self.end+offset)\n",
    "\n",
    "    def with_lines_offset_se(self, offset_s, offset_e):\n",
    "        return Handshake(self._df, self.start-offset_s, self.end+offset_e)\n",
    "\n",
    "    @property\n",
    "    def start_ms(self):\n",
    "        return self._df['timestamp'].iloc[self.start]\n",
    "\n",
    "    @property\n",
    "    def end_ms(self):\n",
    "        return self._df['timestamp'].iloc[self.end]\n",
    "\n",
    "    @property\n",
    "    def duration_ms(self): # in milliseconds\n",
    "        return round((self.end_ms - self.start_ms) * 1000, 2)\n",
    "\n",
    "    @property\n",
    "    def energy_mj(self): # in millijoules\n",
    "        time_step = 0.000250 # seconds\n",
    "        joules = (self.df['power'] * time_step).sum()\n",
    "        return round(joules * 1000, 2)\n",
    "\n",
    "    @property\n",
    "    def power_avg(self):\n",
    "        return self.df['power'].mean()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"\"\"Duration (ms): {self.duration_ms}\n",
    "Energy (mJ): {self.energy_mj}\"\"\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        dic = {\n",
    "            \"duration\": self.duration_ms,\n",
    "            \"energy\": self.energy_mj,\n",
    "        }\n",
    "        return str(dic)\n",
    "\n",
    "class DataLoader:\n",
    "    csv_files_otii = {\n",
    "        \"current\": \"Main current - Arc.csv\",\n",
    "        \"power\": \"Main power - Arc.csv\",\n",
    "        \"gpio\": \"GPI 1 - Arc.csv\",\n",
    "    }\n",
    "\n",
    "    # @lru_cache\n",
    "    def find_handshakes(df):\n",
    "        # convert NaN to an arbitrary integer\n",
    "        df['gpio'] = df['gpio'].fillna(-9).astype(int)\n",
    "\n",
    "        gpio_values = df['gpio'].values\n",
    "        in_handshake = False\n",
    "        hs_start, hs_end = 0, 0\n",
    "        handshakes = []\n",
    "        for index, value in enumerate(gpio_values):\n",
    "            if not in_handshake and value == 1:\n",
    "                in_handshake = True\n",
    "                hs_start = index\n",
    "            elif in_handshake and value == 0:\n",
    "                in_handshake = False\n",
    "                hs_end = index\n",
    "                hs = Handshake(df, hs_start, hs_end)\n",
    "                handshakes.append(hs)\n",
    "\n",
    "            if in_handshake:\n",
    "                gpio_values[index] = 1\n",
    "\n",
    "        # convert temporary value to 0\n",
    "        gpio_values[gpio_values == -9] = 0\n",
    "        # Update the 'gpio' column in the DataFrame\n",
    "        df['gpio'] = gpio_values\n",
    "        return df, handshakes\n",
    "\n",
    "    def run(results_dir):\n",
    "        dfs = []\n",
    "\n",
    "        for source, csv_file in DataLoader.csv_files_otii.items():\n",
    "            filename = f\"{results_dir}/{csv_file}\"\n",
    "            df = pd.read_csv(filename)\n",
    "            df = df.rename(columns={'Timestamp': 'timestamp'})\n",
    "            df = df.rename(columns={'Value': source})\n",
    "            # print(df.head())\n",
    "            dfs.append(df)\n",
    "\n",
    "        merged_df = dfs[0]\n",
    "        for df in dfs[1:]:\n",
    "            merged_df = merged_df.merge(df, on=\"timestamp\", how=\"outer\")\n",
    "\n",
    "        merged_df, handshakes = DataLoader.find_handshakes(merged_df)\n",
    "\n",
    "        return merged_df, handshakes\n",
    "\n",
    "def mean_stdev(arr, ndigits=2):\n",
    "    return round(statistics.mean(arr), ndigits), round(statistics.stdev(arr), ndigits)\n",
    "\n",
    "@dataclass\n",
    "class HandshakeSet:\n",
    "    label: str\n",
    "    csv_folder: str\n",
    "    df: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    handshakes: list = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.df, self.handshakes = DataLoader.run(self.csv_folder)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.handshakes[index]\n",
    "\n",
    "    def duration_mean_stdev(self):\n",
    "        return mean_stdev([hs.duration_ms for hs in self.handshakes])\n",
    "\n",
    "    def energy_mean_stdev(self):\n",
    "        return mean_stdev([hs.energy_mj for hs in self.handshakes])\n",
    "\n",
    "    def power_mean(self):\n",
    "        return round(statistics.mean([hs.power_avg for hs in self.handshakes]), 2)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.summary())\n",
    "\n",
    "    def summary(self):\n",
    "        return {\n",
    "            'label': self.label,\n",
    "            'handshakes': len(self.handshakes),\n",
    "            'duration': self.duration_mean_stdev(),\n",
    "            'energy': self.energy_mean_stdev(),\n",
    "            'power': self.power_mean(),\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class HandshakeMemory():\n",
    "    csv_file: str\n",
    "    df: pd.DataFrame = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.df = pd.read_csv(self.csv_file).set_index('protocol')\n",
    "        self.df = (self.df / 1000) #.astype(int) # convert to kB\n",
    "        self.df['Flash'] = self.df[['text', 'data']].sum(axis=1)\n",
    "        self.df['RAM'] = self.df[['data', 'bss', 'stack']].sum(axis=1)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        colors = {\n",
    "            'text': 'tab:blue',\n",
    "            'data': 'firebrick',\n",
    "            'bss': 'tab:green', \n",
    "            'stack': 'tab:orange'\n",
    "        }\n",
    "        xtick_labels = ['EDHOC', 'DTLS RPK', 'DTLS CERT']\n",
    "\n",
    "        self.df[['data', 'bss', 'stack']].plot(kind='bar', stacked=True, ax=ax1, zorder=5, color=[colors['data'], colors['bss'], colors['stack']])\n",
    "        ax1.set_xticklabels(xtick_labels, rotation=0)  # rotation=0 makes labels horizontal\n",
    "        ax1.set_title('RAM Usage')\n",
    "        ax1.set_xlabel('Protocol')\n",
    "        ax1.set_ylabel('RAM Usage (kB)')\n",
    "\n",
    "        self.df[['text', 'data']].plot(kind='bar', stacked=True, ax=ax2, zorder=5, color=[colors['text'], colors['data']])\n",
    "        ax2.set_xticklabels(xtick_labels, rotation=0)\n",
    "        ax2.set_title('Flash Usage')\n",
    "        ax2.set_xlabel('Protocol')\n",
    "        ax2.set_ylabel('Flash Usage (kB)')\n",
    "\n",
    "        [ax.grid(True, which='both', axis='y', linestyle='--', linewidth=0.5, zorder=1) for ax in [ax1, ax2]]\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.3)\n",
    "        # plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def percentage_of(self, p1='edhoc', p2='dtls_rpk'):\n",
    "        return {\n",
    "            'RAM': round(self.df.loc[p1, 'RAM'] / self.df.loc[p2, 'RAM'] * 100, 2),\n",
    "            'Flash': round(self.df.loc[p1, 'Flash'] / self.df.loc[p2, 'Flash'] * 100, 2),\n",
    "        }\n",
    "\n",
    "    def summary(self):\n",
    "        return {\n",
    "            'text': self.df['text'].to_dict(),\n",
    "            'data': self.df['data'].to_dict(),\n",
    "            'bss': self.df['bss'].to_dict(),\n",
    "            'stack': self.df['stack'].to_dict(),\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class HandshakeLog:\n",
    "    filename: str\n",
    "    target_duration_mean_ms: float\n",
    "    log_text: str = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        with open(self.filename) as f:\n",
    "            self.log_text = f.read()\n",
    "\n",
    "    def get_scaled_timestamps_and_messages(self):\n",
    "        # Parsing log text\n",
    "        timestamps = []\n",
    "        messages = []\n",
    "        for line in self.log_text.strip().split(\"\\n\"):\n",
    "            timestamp_str, message = line.split(\" # \")\n",
    "            timestamp = datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S,%f\")\n",
    "            timestamps.append(timestamp)\n",
    "            messages.append(message)\n",
    "\n",
    "        # Convert timestamps to seconds, starting from 0\n",
    "        start_time = timestamps[0]\n",
    "        timestamps_in_seconds = [(t - start_time).total_seconds() for t in timestamps]\n",
    "        # return timestamps_in_seconds, messages\n",
    "\n",
    "        # Re-scale timestamps to X ms\n",
    "        original_duration = timestamps_in_seconds[-1] - timestamps_in_seconds[0]\n",
    "        target_duration = self.target_duration_mean_ms / 1000\n",
    "        scaling_factor = target_duration / original_duration\n",
    "        rescaled_timestamps_in_seconds = [t * scaling_factor for t in timestamps_in_seconds]\n",
    "\n",
    "        return zip(rescaled_timestamps_in_seconds, messages)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    label: str\n",
    "    csv_folder_edhoc: str\n",
    "    csv_folder_dtls: str\n",
    "    csv_folder_dtls_cert: str\n",
    "    memory: HandshakeMemory\n",
    "    sizes: HandshakeSizes\n",
    "    edhoc_log_file: str = None\n",
    "    dtls_log_file: str = None\n",
    "    dtls_cert_log_file: str = None\n",
    "    edhoc_hs: HandshakeSet = None\n",
    "    dtls_hs: HandshakeSet = None\n",
    "    edhoc_hs_log: HandshakeLog = None\n",
    "    dtls_hs_log: HandshakeLog = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.edhoc_hs = HandshakeSet(\"edhoc\", self.csv_folder_edhoc)\n",
    "        self.dtls_hs = HandshakeSet(\"dtls\", self.csv_folder_dtls)\n",
    "        self.dtls_cert_hs = HandshakeSet(\"dtls\", self.csv_folder_dtls_cert)\n",
    "        if self.edhoc_log_file:\n",
    "            self.edhoc_hs_log = HandshakeLog(self.edhoc_log_file, self.edhoc_hs.duration_mean_stdev()[0])\n",
    "        if self.dtls_log_file:\n",
    "            self.dtls_hs_log = HandshakeLog(self.dtls_log_file, self.dtls_hs.duration_mean_stdev()[0])\n",
    "\n",
    "    def plot_durations(self):\n",
    "        protocols_names = ['EDHOC', 'DTLS RPK', 'DTLS Cert']\n",
    "        df = self.summary_handshakes_df()\n",
    "\n",
    "        # Plotting\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        bar_positions = [0, 0.5]\n",
    "\n",
    "        df['duration_avg'].plot(kind='bar', ax=ax1, yerr=df['duration_std'], capsize=10, zorder=5)\n",
    "        ax1.set_xticklabels(protocols_names, rotation=0)\n",
    "        ax1.set_ylabel('Handshake Duration (ms)')\n",
    "        ax1.set_title('Handshake Duration')\n",
    "\n",
    "        df['energy_avg'].plot(kind='bar', ax=ax2, yerr=df['energy_std'], capsize=10, zorder=5)\n",
    "        ax2.set_xticklabels(protocols_names, rotation=0)\n",
    "        ax2.set_ylabel('Handshake Energy (mJ)')\n",
    "        ax2.set_title('Handshake Energy Consumption')\n",
    "\n",
    "        [ax.grid(True, which='both', axis='y', linestyle='--', linewidth=0.5, zorder=1) for ax in [ax1, ax2]]\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.2)\n",
    "        # plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_handshake_instance(self, hs, protocol, index, os=200, oe=200, plot_logs=False):\n",
    "        offset_hs = hs.with_lines_offset_se(os, oe)\n",
    "\n",
    "        # compute offset difference to milliseconds\n",
    "        offset_start_ms = hs.start_ms - offset_hs.start_ms\n",
    "        offset_end_ms = offset_start_ms + (hs.duration_ms / 1000)\n",
    "\n",
    "        offset_hs._df = offset_hs._df.copy()\n",
    "        # make timestamp being from 0, and also compensate the start (left side) offset\n",
    "        # offset_hs._df['timestamp'] = offset_hs._df['timestamp'] - offset_hs.start_ms\n",
    "        offset_hs._df['timestamp'] = offset_hs._df['timestamp'] - offset_hs.start_ms - offset_start_ms\n",
    "\n",
    "        # convert amps to milliamps\n",
    "        offset_hs._df['current'] = offset_hs._df['current'] * 1000\n",
    "\n",
    "        plt.figure(figsize=(18, 3))\n",
    "        plt.plot(offset_hs.df['timestamp'], offset_hs.df['current'], label='Current (mA)')\n",
    "\n",
    "        if plot_logs:\n",
    "            if \"EDHOC\" in protocol:\n",
    "                # using hs.duration_ms because we want the actual value, not the mean\n",
    "                log = HandshakeLog(self.edhoc_log_file, hs.duration_ms)\n",
    "            elif \"DTLS RPK\" in protocol:\n",
    "                log = HandshakeLog(self.dtls_log_file, hs.duration_ms)\n",
    "            elif \"DTLS Cert\" in protocol:\n",
    "                log = HandshakeLog(self.dtls_cert_log_file, hs.duration_ms)\n",
    "            y_position_for_text = plt.ylim()[1]\n",
    "            for x, message in log.get_scaled_timestamps_and_messages():\n",
    "                if \"begin handshake\" in message or \"end handshake ok\" in message:\n",
    "                    continue\n",
    "                color = 'grey'\n",
    "                linewidth = 1\n",
    "                plt.axvline(x=x, color=color, linestyle='-', linewidth=linewidth)\n",
    "                plt.text(x, y_position_for_text, message, rotation=60, ha='left', va='bottom', fontsize=8)\n",
    "        else:\n",
    "            # add text above\n",
    "            duration_position_x = (offset_hs.start_ms + offset_hs.end_ms) / 2\n",
    "            y_position = plt.ylim()[1] * 1.03\n",
    "            plt.text(duration_position_x, y_position, f\"{protocol} -- handshake #{index}\\n{hs}\", ha='center')\n",
    "\n",
    "        # draw vertical red lines at start and stop\n",
    "        plt.axvline(x=0, color='red')\n",
    "        plt.axvline(x=offset_end_ms-offset_start_ms, color='red', linewidth=2)\n",
    "\n",
    "        # print(offset_hs.df['timestamp'].min(), offset_hs.df['timestamp'].max())\n",
    "        # TODO: this should be automated from min and max, but it is not working\n",
    "        # plt.xlim(0, 0.33)\n",
    "        plt.xlim(0-offset_start_ms, 0.42-offset_start_ms)\n",
    "\n",
    "        plt.xlabel('Timestamp (s)')\n",
    "        plt.ylabel('Current (mA)')\n",
    "        plt.grid(True, which='both', axis='y', linestyle='--', linewidth=0.5, zorder=1)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # def plot_handshake_instance_comparison(self, edhoc_hs, dtls_hs, index, plot_logs=False):\n",
    "    #     offset_for_larger_left = offset_for_smaller_left = 100\n",
    "    #     offset_for_larger_right = 200\n",
    "    #     offset_for_smaller_right = ((dtls_hs.end - dtls_hs.start) - (edhoc_hs.end - edhoc_hs.start)) + offset_for_larger_right\n",
    "\n",
    "    #     self.plot_handshake_instance(edhoc_hs, \"EDHOC\", index, offset_for_smaller_left, offset_for_smaller_right, plot_logs)\n",
    "    #     self.plot_handshake_instance(dtls_hs, \"DTLS RPK\", index, offset_for_larger_left, offset_for_larger_right, plot_logs)\n",
    "\n",
    "    def plot_handshake_instance_comparison(self, edhoc_hs, dtls_hs, dtls_cert_hs, index, plot_logs=False):\n",
    "        offset_left = 100\n",
    "        offset_for_larger_right = 200\n",
    "        offset_for_edhoc_right = ((dtls_cert_hs.end - dtls_cert_hs.start) - (edhoc_hs.end - edhoc_hs.start)) + offset_for_larger_right\n",
    "        offset_for_dtls_right = ((dtls_cert_hs.end - dtls_cert_hs.start) - (dtls_hs.end - dtls_hs.start)) + offset_for_larger_right\n",
    "\n",
    "        self.plot_handshake_instance(edhoc_hs, \"EDHOC\", index, offset_left, offset_for_edhoc_right, plot_logs)\n",
    "        self.plot_handshake_instance(dtls_hs, \"DTLS RPK\", index, offset_left, offset_for_dtls_right, plot_logs)\n",
    "        self.plot_handshake_instance(dtls_cert_hs, \"DTLS Cert\", index, offset_left, offset_for_larger_right, plot_logs)\n",
    "\n",
    "    def summary_handshakes_df(self):\n",
    "        edhoc_sum = self.edhoc_hs.summary()\n",
    "        dtls_sum = self.dtls_hs.summary()\n",
    "        dtls_cert_sum = self.dtls_cert_hs.summary()\n",
    "        df = pd.DataFrame({\n",
    "            'protocol': ['edhoc', 'dtls_rpk', 'dtls_cert'],\n",
    "            'handshakes': [edhoc_sum['handshakes'], dtls_sum['handshakes'], dtls_cert_sum['handshakes']],\n",
    "            'duration_avg': [edhoc_sum['duration'][0], dtls_sum['duration'][0], dtls_cert_sum['duration'][0]],\n",
    "            'duration_std': [edhoc_sum['duration'][1], dtls_sum['duration'][1], dtls_cert_sum['duration'][1]],\n",
    "            'energy_avg': [edhoc_sum['energy'][0], dtls_sum['energy'][0], dtls_cert_sum['energy'][0]],\n",
    "            'energy_std': [edhoc_sum['energy'][1], dtls_sum['energy'][1], dtls_cert_sum['energy'][1]],\n",
    "            'power_avg': [edhoc_sum['power'], dtls_sum['power'], dtls_cert_sum['power']],\n",
    "        })\n",
    "        df.set_index('protocol', inplace=True)\n",
    "        return df\n",
    "\n",
    "    def handshakes_percentage_of(self, p1='edhoc', p2='dtls_rpk'):\n",
    "        df = self.summary_handshakes_df()\n",
    "        return {\n",
    "            'Duration': round(df.loc[p1, 'duration_avg'] / df.loc[p2, 'duration_avg'] * 100, 2),\n",
    "            'Energy': round(df.loc[p1, 'energy_avg'] / df.loc[p2, 'energy_avg'] * 100, 2),\n",
    "        }\n",
    "\n",
    "    def summary(self):\n",
    "        return {\n",
    "            'label': self.label,\n",
    "            'edhoc_hs': self.edhoc_hs.summary(),\n",
    "            'dtls_hs': self.dtls_hs.summary(),\n",
    "            'memory': self.memory.summary(),\n",
    "        }\n",
    "\n",
    "    def results(self, cmp_idx=0, peek=False):\n",
    "        print_markdown(\"# Summary: \")\n",
    "        res = self.handshakes_percentage_of()\n",
    "        res.update(self.memory.percentage_of())\n",
    "        rich.print(f\"EDHOC percentage of DTLS RPK: {res}\")\n",
    "        res = self.handshakes_percentage_of(p2='dtls_cert')\n",
    "        res.update(self.memory.percentage_of(p2='dtls_cert'))\n",
    "        rich.print(f\"EDHOC percentage of DTLS Cert: {res}\")\n",
    "\n",
    "        print_markdown(\"# Handshake duration and energy (ms, mJ, mW): \")\n",
    "        display(self.summary_handshakes_df())\n",
    "        rich.print(f\"EDHOC percentage of DTLS RPK: {self.handshakes_percentage_of()}\")\n",
    "        rich.print(f\"EDHOC percentage of DTLS Cert: {self.handshakes_percentage_of(p2='dtls_cert')}\")\n",
    "        print(\"Chart: \")\n",
    "        self.plot_durations()\n",
    "\n",
    "        print_markdown(\"# Memory usage (kB): \")\n",
    "        display(self.memory.df)\n",
    "        rich.print(f\"EDHOC percentage of DTLS RPK: {self.memory.percentage_of()}\")\n",
    "        rich.print(f\"EDHOC percentage of DTLS Cert: {self.memory.percentage_of(p2='dtls_cert')}\")\n",
    "        print(\"Chart: \")\n",
    "        self.memory.plot()\n",
    "\n",
    "        self.sizes.results(plot=True)\n",
    "\n",
    "        if peek:\n",
    "            print_markdown(\"# A peek at one particular handshake (red lines mean start/stop of the handshake procedure): \")\n",
    "            self.plot_handshake_instance_comparison(self.edhoc_hs[cmp_idx], self.dtls_hs[cmp_idx], self.dtls_cert_hs[cmp_idx], cmp_idx, plot_logs=False)\n",
    "\n",
    "            print_markdown(\"# A peek at one particular handshake, with logs*: \")\n",
    "            print_markdown(\"*note that there are significant skew due to collecting logs with serial port ON.\")\n",
    "            self.plot_handshake_instance_comparison(self.edhoc_hs[cmp_idx], self.dtls_hs[cmp_idx], self.dtls_cert_hs[cmp_idx], cmp_idx, plot_logs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "980fa751",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: \"['61dc412300e08d6f790bd634ba80164079cdc0956e']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39medhoc_vs_dtls-09aug\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./results/edhoc-21aug-16h22-csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./results/dtls-21aug-16h26-csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./results/dtls-30aug-14h52-csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[39m# HandshakeMemory(\"./results/memory-2023-08-21_15:55:20.csv\"),\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     HandshakeMemory(\u001b[39m\"\u001b[39m\u001b[39m./results/memory-2023-08-30_14:28:09.csv\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m----> 8\u001b[0m     HandshakeSizes(\u001b[39m\"\u001b[39;49m\u001b[39m./results/edhoc_pcap.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m./results/dtls_rpk_pcap.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m./results/dtls_cert_pcap.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./results/edhoc_rs.log\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./results/dtls-rpk-wolfssl.log\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m./results/dtls-cert-wolfssl.log\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m experiment\u001b[39m.\u001b[39mresults(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<string>:9\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, edhoc_csv_file, dtls_csv_file, dtls_cert_csv_file, edhoc_df, dtls_df, dtls_cert_df)\u001b[0m\n",
      "Cell \u001b[0;32mIn[161], line 24\u001b[0m, in \u001b[0;36mHandshakeSizes.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medhoc_df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medhoc_df\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m_total\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medhoc_df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39m_direction\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msum(numeric_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medhoc_df \u001b[39m=\u001b[39m HandshakeSizes\u001b[39m.\u001b[39;49menforce_int(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medhoc_df)\n\u001b[1;32m     26\u001b[0m dtls_steps \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mClient Hello\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mServer Hello\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mClient Hello (cookie)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mServer Hello\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEncrypted Extensions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCertificate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCertificate Verify\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mServer Finished\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mClient Finished\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAck\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtls_df\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m, dtls_steps)\n",
      "Cell \u001b[0;32mIn[161], line 12\u001b[0m, in \u001b[0;36mHandshakeSizes.enforce_int\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menforce_int\u001b[39m(df):\n\u001b[1;32m     11\u001b[0m     columns_to_convert \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m_direction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_data_no_radio\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m---> 12\u001b[0m     df[columns_to_convert] \u001b[39m=\u001b[39m df[columns_to_convert]\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6324\u001b[0m, in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6299\u001b[0m \u001b[39m@doc\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_shared_doc_kwargs)\n\u001b[1;32m   6300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfillna\u001b[39m(\n\u001b[1;32m   6301\u001b[0m     \u001b[39mself\u001b[39m: NDFrameT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6307\u001b[0m     downcast\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   6308\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6309\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6310\u001b[0m \u001b[39m    Fill NA/NaN values using the specified method.\u001b[39;00m\n\u001b[1;32m   6311\u001b[0m \n\u001b[1;32m   6312\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   6313\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m   6314\u001b[0m \u001b[39m    value : scalar, dict, Series, or DataFrame\u001b[39;00m\n\u001b[1;32m   6315\u001b[0m \u001b[39m        Value to use to fill holes (e.g. 0), alternately a\u001b[39;00m\n\u001b[1;32m   6316\u001b[0m \u001b[39m        dict/Series/DataFrame of values specifying which value to use for\u001b[39;00m\n\u001b[1;32m   6317\u001b[0m \u001b[39m        each index (for a Series) or column (for a DataFrame).  Values not\u001b[39;00m\n\u001b[1;32m   6318\u001b[0m \u001b[39m        in the dict/Series/DataFrame will not be filled. This value cannot\u001b[39;00m\n\u001b[1;32m   6319\u001b[0m \u001b[39m        be a list.\u001b[39;00m\n\u001b[1;32m   6320\u001b[0m \u001b[39m    method : {{'backfill', 'bfill', 'pad', 'ffill', None}}, default None\u001b[39;00m\n\u001b[1;32m   6321\u001b[0m \u001b[39m        Method to use for filling holes in reindexed Series\u001b[39;00m\n\u001b[1;32m   6322\u001b[0m \u001b[39m        pad / ffill: propagate last valid observation forward to next valid\u001b[39;00m\n\u001b[1;32m   6323\u001b[0m \u001b[39m        backfill / bfill: use next valid observation to fill gap.\u001b[39;00m\n\u001b[0;32m-> 6324\u001b[0m \u001b[39m    axis : {axes_single_arg}\u001b[39;00m\n\u001b[1;32m   6325\u001b[0m \u001b[39m        Axis along which to fill missing values.\u001b[39;00m\n\u001b[1;32m   6326\u001b[0m \u001b[39m    inplace : bool, default False\u001b[39;00m\n\u001b[1;32m   6327\u001b[0m \u001b[39m        If True, fill in-place. Note: this will modify any\u001b[39;00m\n\u001b[1;32m   6328\u001b[0m \u001b[39m        other views on this object (e.g., a no-copy slice for a column in a\u001b[39;00m\n\u001b[1;32m   6329\u001b[0m \u001b[39m        DataFrame).\u001b[39;00m\n\u001b[1;32m   6330\u001b[0m \u001b[39m    limit : int, default None\u001b[39;00m\n\u001b[1;32m   6331\u001b[0m \u001b[39m        If method is specified, this is the maximum number of consecutive\u001b[39;00m\n\u001b[1;32m   6332\u001b[0m \u001b[39m        NaN values to forward/backward fill. In other words, if there is\u001b[39;00m\n\u001b[1;32m   6333\u001b[0m \u001b[39m        a gap with more than this number of consecutive NaNs, it will only\u001b[39;00m\n\u001b[1;32m   6334\u001b[0m \u001b[39m        be partially filled. If method is not specified, this is the\u001b[39;00m\n\u001b[1;32m   6335\u001b[0m \u001b[39m        maximum number of entries along the entire axis where NaNs will be\u001b[39;00m\n\u001b[1;32m   6336\u001b[0m \u001b[39m        filled. Must be greater than 0 if not None.\u001b[39;00m\n\u001b[1;32m   6337\u001b[0m \u001b[39m    downcast : dict, default is None\u001b[39;00m\n\u001b[1;32m   6338\u001b[0m \u001b[39m        A dict of item->dtype of what to downcast if possible,\u001b[39;00m\n\u001b[1;32m   6339\u001b[0m \u001b[39m        or the string 'infer' which will try to downcast to an appropriate\u001b[39;00m\n\u001b[1;32m   6340\u001b[0m \u001b[39m        equal type (e.g. float64 to int64 if possible).\u001b[39;00m\n\u001b[1;32m   6341\u001b[0m \n\u001b[1;32m   6342\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[1;32m   6343\u001b[0m \u001b[39m    -------\u001b[39;00m\n\u001b[1;32m   6344\u001b[0m \u001b[39m    {klass} or None\u001b[39;00m\n\u001b[1;32m   6345\u001b[0m \u001b[39m        Object with missing values filled or None if ``inplace=True``.\u001b[39;00m\n\u001b[1;32m   6346\u001b[0m \n\u001b[1;32m   6347\u001b[0m \u001b[39m    See Also\u001b[39;00m\n\u001b[1;32m   6348\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m   6349\u001b[0m \u001b[39m    interpolate : Fill NaN values using interpolation.\u001b[39;00m\n\u001b[1;32m   6350\u001b[0m \u001b[39m    reindex : Conform object to new index.\u001b[39;00m\n\u001b[1;32m   6351\u001b[0m \u001b[39m    asfreq : Convert TimeSeries to specified frequency.\u001b[39;00m\n\u001b[1;32m   6352\u001b[0m \n\u001b[1;32m   6353\u001b[0m \u001b[39m    Examples\u001b[39;00m\n\u001b[1;32m   6354\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m   6355\u001b[0m \u001b[39m    >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\u001b[39;00m\n\u001b[1;32m   6356\u001b[0m \u001b[39m    ...                    [3, 4, np.nan, 1],\u001b[39;00m\n\u001b[1;32m   6357\u001b[0m \u001b[39m    ...                    [np.nan, np.nan, np.nan, np.nan],\u001b[39;00m\n\u001b[1;32m   6358\u001b[0m \u001b[39m    ...                    [np.nan, 3, np.nan, 4]],\u001b[39;00m\n\u001b[1;32m   6359\u001b[0m \u001b[39m    ...                   columns=list(\"ABCD\"))\u001b[39;00m\n\u001b[1;32m   6360\u001b[0m \u001b[39m    >>> df\u001b[39;00m\n\u001b[1;32m   6361\u001b[0m \u001b[39m         A    B   C    D\u001b[39;00m\n\u001b[1;32m   6362\u001b[0m \u001b[39m    0  NaN  2.0 NaN  0.0\u001b[39;00m\n\u001b[1;32m   6363\u001b[0m \u001b[39m    1  3.0  4.0 NaN  1.0\u001b[39;00m\n\u001b[1;32m   6364\u001b[0m \u001b[39m    2  NaN  NaN NaN  NaN\u001b[39;00m\n\u001b[1;32m   6365\u001b[0m \u001b[39m    3  NaN  3.0 NaN  4.0\u001b[39;00m\n\u001b[1;32m   6366\u001b[0m \n\u001b[1;32m   6367\u001b[0m \u001b[39m    Replace all NaN elements with 0s.\u001b[39;00m\n\u001b[1;32m   6368\u001b[0m \n\u001b[1;32m   6369\u001b[0m \u001b[39m    >>> df.fillna(0)\u001b[39;00m\n\u001b[1;32m   6370\u001b[0m \u001b[39m         A    B    C    D\u001b[39;00m\n\u001b[1;32m   6371\u001b[0m \u001b[39m    0  0.0  2.0  0.0  0.0\u001b[39;00m\n\u001b[1;32m   6372\u001b[0m \u001b[39m    1  3.0  4.0  0.0  1.0\u001b[39;00m\n\u001b[1;32m   6373\u001b[0m \u001b[39m    2  0.0  0.0  0.0  0.0\u001b[39;00m\n\u001b[1;32m   6374\u001b[0m \u001b[39m    3  0.0  3.0  0.0  4.0\u001b[39;00m\n\u001b[1;32m   6375\u001b[0m \n\u001b[1;32m   6376\u001b[0m \u001b[39m    We can also propagate non-null values forward or backward.\u001b[39;00m\n\u001b[1;32m   6377\u001b[0m \n\u001b[1;32m   6378\u001b[0m \u001b[39m    >>> df.fillna(method=\"ffill\")\u001b[39;00m\n\u001b[1;32m   6379\u001b[0m \u001b[39m         A    B   C    D\u001b[39;00m\n\u001b[1;32m   6380\u001b[0m \u001b[39m    0  NaN  2.0 NaN  0.0\u001b[39;00m\n\u001b[1;32m   6381\u001b[0m \u001b[39m    1  3.0  4.0 NaN  1.0\u001b[39;00m\n\u001b[1;32m   6382\u001b[0m \u001b[39m    2  3.0  4.0 NaN  1.0\u001b[39;00m\n\u001b[1;32m   6383\u001b[0m \u001b[39m    3  3.0  3.0 NaN  4.0\u001b[39;00m\n\u001b[1;32m   6384\u001b[0m \n\u001b[1;32m   6385\u001b[0m \u001b[39m    Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\u001b[39;00m\n\u001b[1;32m   6386\u001b[0m \u001b[39m    2, and 3 respectively.\u001b[39;00m\n\u001b[1;32m   6387\u001b[0m \n\u001b[1;32m   6388\u001b[0m \u001b[39m    >>> values = {{\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}}\u001b[39;00m\n\u001b[1;32m   6389\u001b[0m \u001b[39m    >>> df.fillna(value=values)\u001b[39;00m\n\u001b[1;32m   6390\u001b[0m \u001b[39m         A    B    C    D\u001b[39;00m\n\u001b[1;32m   6391\u001b[0m \u001b[39m    0  0.0  2.0  2.0  0.0\u001b[39;00m\n\u001b[1;32m   6392\u001b[0m \u001b[39m    1  3.0  4.0  2.0  1.0\u001b[39;00m\n\u001b[1;32m   6393\u001b[0m \u001b[39m    2  0.0  1.0  2.0  3.0\u001b[39;00m\n\u001b[1;32m   6394\u001b[0m \u001b[39m    3  0.0  3.0  2.0  4.0\u001b[39;00m\n\u001b[1;32m   6395\u001b[0m \n\u001b[1;32m   6396\u001b[0m \u001b[39m    Only replace the first NaN element.\u001b[39;00m\n\u001b[1;32m   6397\u001b[0m \n\u001b[1;32m   6398\u001b[0m \u001b[39m    >>> df.fillna(value=values, limit=1)\u001b[39;00m\n\u001b[1;32m   6399\u001b[0m \u001b[39m         A    B    C    D\u001b[39;00m\n\u001b[1;32m   6400\u001b[0m \u001b[39m    0  0.0  2.0  2.0  0.0\u001b[39;00m\n\u001b[1;32m   6401\u001b[0m \u001b[39m    1  3.0  4.0  NaN  1.0\u001b[39;00m\n\u001b[1;32m   6402\u001b[0m \u001b[39m    2  NaN  1.0  NaN  3.0\u001b[39;00m\n\u001b[1;32m   6403\u001b[0m \u001b[39m    3  NaN  3.0  NaN  4.0\u001b[39;00m\n\u001b[1;32m   6404\u001b[0m \n\u001b[1;32m   6405\u001b[0m \u001b[39m    When filling using a DataFrame, replacement happens along\u001b[39;00m\n\u001b[1;32m   6406\u001b[0m \u001b[39m    the same column names and same indices\u001b[39;00m\n\u001b[1;32m   6407\u001b[0m \n\u001b[1;32m   6408\u001b[0m \u001b[39m    >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\u001b[39;00m\n\u001b[1;32m   6409\u001b[0m \u001b[39m    >>> df.fillna(df2)\u001b[39;00m\n\u001b[1;32m   6410\u001b[0m \u001b[39m         A    B    C    D\u001b[39;00m\n\u001b[1;32m   6411\u001b[0m \u001b[39m    0  0.0  2.0  0.0  0.0\u001b[39;00m\n\u001b[1;32m   6412\u001b[0m \u001b[39m    1  3.0  4.0  0.0  1.0\u001b[39;00m\n\u001b[1;32m   6413\u001b[0m \u001b[39m    2  0.0  0.0  0.0  NaN\u001b[39;00m\n\u001b[1;32m   6414\u001b[0m \u001b[39m    3  0.0  3.0  0.0  4.0\u001b[39;00m\n\u001b[1;32m   6415\u001b[0m \n\u001b[1;32m   6416\u001b[0m \u001b[39m    Note that column D is not affected since it is not present in df2.\u001b[39;00m\n\u001b[1;32m   6417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6418\u001b[0m     inplace \u001b[39m=\u001b[39m validate_bool_kwarg(inplace, \u001b[39m\"\u001b[39m\u001b[39minplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6419\u001b[0m     value, method \u001b[39m=\u001b[39m validate_fillna_kwargs(value, method)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:451\u001b[0m, in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_regex\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\u001b[39m\"\u001b[39m\u001b[39m_replace_regex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_list\u001b[39m(\n\u001b[1;32m    449\u001b[0m     \u001b[39mself\u001b[39m: T,\n\u001b[1;32m    450\u001b[0m     src_list: \u001b[39mlist\u001b[39m[Any],\n\u001b[0;32m--> 451\u001b[0m     dest_list: \u001b[39mlist\u001b[39m[Any],\n\u001b[1;32m    452\u001b[0m     inplace: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    453\u001b[0m     regex: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    454\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    455\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     inplace \u001b[39m=\u001b[39m validate_bool_kwarg(inplace, \u001b[39m\"\u001b[39m\u001b[39minplace\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     align_keys \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    345\u001b[0m     new \u001b[39m=\u001b[39m extract_array(new, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    347\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\n\u001b[1;32m    348\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mputmask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m     align_keys\u001b[39m=\u001b[39malign_keys,\n\u001b[1;32m    350\u001b[0m     mask\u001b[39m=\u001b[39mmask,\n\u001b[1;32m    351\u001b[0m     new\u001b[39m=\u001b[39mnew,\n\u001b[0;32m--> 352\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:511\u001b[0m, in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    507\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit_and_operate\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[1;32m    508\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m    Split the block and apply func column-by-column.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m--> 511\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[39m    func : Block method\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[39m    *args\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39m    **kwargs\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[39m    -------\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m    List[Block]\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    521\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    523\u001b[0m     res_blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: \"['61dc412300e08d6f790bd634ba80164079cdc0956e']\""
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "    \"edhoc_vs_dtls-09aug\",\n",
    "    \"./results/edhoc-21aug-16h22-csv\",\n",
    "    \"./results/dtls-21aug-16h26-csv\",\n",
    "    \"./results/dtls-30aug-14h52-csv\",\n",
    "    # HandshakeMemory(\"./results/memory-2023-08-21_15:55:20.csv\"),\n",
    "    HandshakeMemory(\"./results/memory-2023-08-30_14:28:09.csv\"),\n",
    "    HandshakeSizes(\"./results/edhoc_pcap.csv\", \"./results/dtls_rpk_pcap.csv\", \"./results/dtls_cert_pcap.csv\"),\n",
    "    \"./results/edhoc_rs.log\",\n",
    "    \"./results/dtls-rpk-wolfssl.log\",\n",
    "    \"./results/dtls-cert-wolfssl.log\",\n",
    ")\n",
    "\n",
    "experiment.results(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c4c536c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "src",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:455\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:450\u001b[0m, in \u001b[0;36mPacket.getfield_and_val\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_field(attr), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_fields[attr]\n\u001b[0;32m--> 450\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:455\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:450\u001b[0m, in \u001b[0;36mPacket.getfield_and_val\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_field(attr), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_fields[attr]\n\u001b[0;32m--> 450\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:455\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:450\u001b[0m, in \u001b[0;36mPacket.getfield_and_val\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_field(attr), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_fields[attr]\n\u001b[0;32m--> 450\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:455\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:450\u001b[0m, in \u001b[0;36mPacket.getfield_and_val\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_field(attr), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_fields[attr]\n\u001b[0;32m--> 450\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/formatters.py:708\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    701\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    702\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    703\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[1;32m    704\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[1;32m    705\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[1;32m    706\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[1;32m    707\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 708\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[1;32m    709\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    710\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/lib/pretty.py:393\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m _get_mro(obj_class):\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_pprinters:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# printer registered in self.type_pprinters\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtype_pprinters[\u001b[39mcls\u001b[39;49m](obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    394\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m         \u001b[39m# deferred printer\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         printer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_deferred_types(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/lib/pretty.py:640\u001b[0m, in \u001b[0;36m_seq_pprinter_factory.<locals>.inner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    638\u001b[0m         p\u001b[39m.\u001b[39mtext(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    639\u001b[0m         p\u001b[39m.\u001b[39mbreakable()\n\u001b[0;32m--> 640\u001b[0m     p\u001b[39m.\u001b[39;49mpretty(x)\n\u001b[1;32m    641\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    642\u001b[0m     \u001b[39m# Special case for 1-item tuples.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     p\u001b[39m.\u001b[39mtext(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[1;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "Cell \u001b[0;32mIn[109], line 27\u001b[0m, in \u001b[0;36mMyPacket.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39m({\n\u001b[1;32m     25\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlen\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m),\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlen_no_154\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlen_no_154(),\n\u001b[0;32m---> 27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdirection\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdirection()\n\u001b[1;32m     28\u001b[0m     })\n",
      "Cell \u001b[0;32mIn[109], line 18\u001b[0m, in \u001b[0;36mMyPacket.direction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdirection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mup\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpac\u001b[39m.\u001b[39;49msrc \u001b[39m==\u001b[39m SRC_ADDR \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdown\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:457\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpayload\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(attr)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m fld \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m v \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, RawVal) \u001b[39melse\u001b[39;00m fld\u001b[39m.\u001b[39mi2h(\u001b[39mself\u001b[39m, v)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:457\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpayload\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(attr)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m fld \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m v \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, RawVal) \u001b[39melse\u001b[39;00m fld\u001b[39m.\u001b[39mi2h(\u001b[39mself\u001b[39m, v)\n",
      "    \u001b[0;31m[... skipping similar frames: Packet.__getattr__ at line 457 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:457\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    455\u001b[0m     fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpayload\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(attr)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m fld \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m v \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, RawVal) \u001b[39melse\u001b[39;00m fld\u001b[39m.\u001b[39mi2h(\u001b[39mself\u001b[39m, v)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:455\u001b[0m, in \u001b[0;36mPacket.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr):\n\u001b[1;32m    453\u001b[0m     \u001b[39m# type: (str) -> Any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m         fld, v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetfield_and_val(attr)\n\u001b[1;32m    456\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpayload\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scapy/packet.py:1764\u001b[0m, in \u001b[0;36mNoPayload.getfield_and_val\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetfield_and_val\u001b[39m(\u001b[39mself\u001b[39m, attr):\n\u001b[1;32m   1763\u001b[0m     \u001b[39m# type: (str) -> NoReturn\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr)\n",
      "\u001b[0;31mAttributeError\u001b[0m: src"
     ]
    }
   ],
   "source": [
    "from scapy.all import rdpcap, conf, Packet as ScapyPacket\n",
    "\n",
    "conf.dot15d4_protocol = 'sixlowpan'\n",
    "IEEE_802154_HEADER_LEN = 2+1+2+8+8\n",
    "ORIGINATOR_SRC_ADDR = 'fe80::6c95:c0cd:7940:1680'\n",
    "\n",
    "@dataclass\n",
    "class MyPacket:\n",
    "    pac: ScapyPacket\n",
    "\n",
    "    # def __post_init__(self):\n",
    "    #     self.original_len = len(self.pac.original)\n",
    "\n",
    "    def len_no_154(self):\n",
    "        return len(self) - IEEE_802154_HEADER_LEN\n",
    "\n",
    "    def direction(self):\n",
    "        return \"up\" if self.pac.src == SRC_ADDR else \"down\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pac.original)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str({\n",
    "            \"len\": len(self),\n",
    "            \"len_no_154\": self.len_no_154(),\n",
    "            \"direction\": self.direction()\n",
    "        })\n",
    "\n",
    "def packet_hex(packet):\n",
    "    return packet.original.hex()\n",
    "\n",
    "def remove_802154(packet):\n",
    "    return packet[IEEE_802154_HEADER_LEN:]\n",
    "\n",
    "def load(pcap_file):\n",
    "    packets = rdpcap(pcap_file)\n",
    "    # plens = [len(packet.build()) for packet in packets]\n",
    "    packets = [MyPacket(scapy_packet) for scapy_packet in rdpcap(pcap_file)]\n",
    "    # rich.print(packets)\n",
    "    return packets\n",
    "\n",
    "# load('./results/edhoc.pcap')\n",
    "# load('./results/dtls_rpk.pcap')\n",
    "ps = load('./results/dtls_cert.pcap')\n",
    "ps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "name": "EDHOC x DTLS comparison"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
